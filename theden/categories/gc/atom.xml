<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Gc | Bear Metal]]></title>
  <link href="https://bearmetal.eu/theden/categories/gc/atom.xml" rel="self"/>
  <link href="https://bearmetal.eu/"/>
  <updated>2015-03-13T10:10:58+02:00</updated>
  <id>https://bearmetal.eu/</id>
  <author>
    <name><![CDATA[Bear Metal OÜ]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How Do I Know Whether My Rails App Is Thread-safe or Not?]]></title>
    <link href="https://bearmetal.eu/theden/how-do-i-know-whether-my-rails-app-is-thread-safe-or-not/"/>
    <updated>2015-03-13T10:10:58+02:00</updated>
    <id>https://bearmetal.eu/theden/how-do-i-know-whether-my-rails-app-is-thread-safe-or-not</id>
    <content type="html"><![CDATA[<p>In January <a href="https://devcenter.heroku.com/changelog-items/594">Heroku started promoting</a> <a href="http://puma.io">Puma</a> as the preferred web server for Rails apps deployed on its hugely successful platform. Puma – as a threaded app server – can better use the scarce resources available for an app running on Heroku.</p>

<p>This is obviously good for a client since they can now run more concurrent users with a single Dyno. However, it’s also good for Heroku itself since small apps (probably the vast majority of apps deployed on Heroku) will now consume much fewer resources on its servers.</p>

<p>The recommendation comes with a caveat, however. <em>Your app needs to be thread-safe</em>. The problem with this is that there is no simple way to say with absolute certainty whether an app as a whole is thread-safe. We can get close, however.</p>

<p>Let’s have a look how.</p>

<p>For the purpose of this issue, an app can be split into three parts:</p>

<ol>
<li>The app code itself.</li>
<li>Rails the framework.</li>
<li>Any 3rd party gems used by the app.</li>
</ol>


<p>All three of these need to be thread-safe. Rails and its included gems <a href="http://m.onkey.org/thread-safety-for-your-rails">have been declared thread-safe since 2.2</a>, i.e. since 2008. This alone, however, does <em>not</em> automatically make your app as a whole so. Your own app code and all the gems you use need to be thread-safe as well.</p>

<h2>What is and what isn’t thread-safe in Ruby?</h2>

<p><strong>So when is your app code not thread-safe? Simply put, when you share mutable state between threads in your app.</strong></p>

<p>But what does this even mean?</p>

<p><strong>None of the core data structures (except for Queue) in Ruby are thread-safe</strong>. The structures are mutable, and when shared between threads, there are no guarantees the threads won’t overwrite each others’ changes. Fortunately, this is rarely the case in Rails apps.</p>

<p><strong>Any code that is more than a single operation (as in a single Ruby code call implemented in C) is not thread-safe.</strong> The classic example of this is the <code>+=</code> operator, which is in fact two operations combined, <code>=</code> and <code>+</code>. Thus, the final value of the shared variable in the following code is undetermined:</p>

<pre><code class="ruby">@n = 0
3.times do
  Thread.start { 100.times { @n += 1 } }
end
</code></pre>

<p>However, none of the two above things alone makes code thread-unsafe. It only becomes so when it is mated with shared data. Let’s get back to that in a minute, but first…</p>

<h2>Aside: <strong>But what about GIL?</strong></h2>

<p>More informed readers might object at this point and point out that MRI Ruby uses a GIL, a.k.a. Global Interpreter Lock.</p>

<p>The general wisdom on the street is that GIL is bad because it does not let your threads run in parallel (true, in a sense), but good, because it makes your code thread-safe.</p>

<p>Unfortunately, <strong>GIL <em>does not</em> make your code thread-safe</strong>. It only guarantees that two threads can’t run Ruby code at the same time. Thus it does inhibit parallelism. However, threads can still be paused and resumed at any given point, which means that they absolutely can clobber each others’ data.</p>

<p>GIL does accidentally make some operations (such as <code>Array#&lt;&lt;</code>) atomic. However, there are two issues with this:</p>

<ul>
<li>It only applies to cases where what you’re doing is truly a single Ruby operation. When what you’re doing is multiple operations, context switches can and will happen, and you won’t be happy.</li>
<li>It only applies to MRI. JRuby and Rubinius support true parallelism and thus don’t use a GIL. I wouldn’t count on GIL being there forever for MRI either, so relying on it guaranteeing your code being thread-safe is irresponsible at best.</li>
</ul>


<p>Go read Jesse Storimer’s <a href="http://www.jstorimer.com/blogs/workingwithcode/8085491-nobody-understands-the-gil">Nobody understands the GIL</a> (also parts <a href="http://www.jstorimer.com/blogs/workingwithcode/8100871-nobody-understands-the-gil-part-2-implementation">2</a> and <a href="http://www.rubyinside.com/does-the-gil-make-your-ruby-code-thread-safe-6051.html">3</a>) for much more detail about it (than you can probably even stomach). But for the love of the flying spaghetti monster, <em>don’t count on it making your app thread-safe</em>.</p>

<h2>Thread-safety in Rails the framework</h2>

<p>A bit of history:</p>

<p>Rails and its dependencies were declared thread-safe already in version 2.2, in 2008. At that point, however, the consensus was that so many third party libraries were not thread-safe that the whole request in Rails was enclosed within a giant mutex lock. This meant that while a request was being processed, no other thread in the same process could be running.</p>

<p>In order to take advantage of threaded execution, you had to declare in your config.rb that you really wanted to ditch the lock:</p>

<pre><code class="ruby">config.threadsafe!
</code></pre>

<p>However, en route to Rails 4 <a href="http://tenderlovemaking.com/2012/06/18/removing-config-threadsafe.html">Aaron Tenderlove Patterson demonstrated</a> that what <code>config.threadsafe!</code> did was</p>

<ul>
<li>effectively irrelevant in multi-process environments (such as Unicorn), where a single process never processed multiple requests concurrently.</li>
<li>absolutely necessary every time you used a threaded server such as Puma or Passenger Enterprise.</li>
</ul>


<p>What this meant was that there was no reason for <em>not</em> to have the thread-safe option always on. And that was exactly what was done for Rails 4 in 2012.</p>

<p><strong>Key takeaway: Rails and its dependencies are thread-safe. You don’t have to do anything to “turn that feature on”.</strong></p>

<h2>Making your app code thread-safe</h2>

<p>Good news&colon; Since Rails uses the <a href="http://en.wikipedia.org/wiki/Shared_nothing_architecture">Shared nothing architecture</a>, Rails apps are consequentially very suitable for being thread-safe as well. In general, Rails creates a new controller object of every HTTP request, and everything else flows from there. This isolates most objects in a Rails app from other requests.</p>

<p>Like noted above, built-in Ruby data structures (save for Queue) are not thread-safe. This does not, however, matter, unless you are actually sharing them between threads. Because of the way in which Rails is architectured, this almost never happens in a Rails app.</p>

<p>There are, however, some patterns that can come bite you in the ass when you want to switch to a threaded app server.</p>

<h3>Global variables</h3>

<p>Global variables are, well, global. This means that they are shared between threads. If you weren’t convinced about not using global variables by now, here’s another reason to never touch them. If you really want to share something globally across an app, you are more than likely better served by a constant (but see below), anyway.</p>

<h3>Class variables</h3>

<p>For the purpose of a discussion about threads, class variables are not much different from global variables. They are shared across threads just the same way.</p>

<p>The problem isn’t so much about using class variables, but about mutating them. And if you are not going to mutate a class variable, in many cases a constant is again a better choice.</p>

<h3>Class instance variables</h3>

<p>But maybe you’ve read that you should always use class instance variables instead of class variables in Ruby. Well, maybe you should, but they are just as problematic for threaded programs as class variables.</p>

<p>It’s worth pointing out that both class variables and class instance variables can also be set by class methods. This isn’t such an issue in your own code, but you can easily fall into this trap when calling other apis. Here’s an <a href="http://m.onkey.org/thread-safety-for-your-rails">example from Pratik Naik</a> where the app developer is getting into thread-unsafe territory by just calling Rails class methods:</p>

<pre><code class="ruby">class HomeController &lt; ApplicationController
  before_filter :set_site

  def index
  end

  private

  def set_site
    @site = Site.find_by_subdomain(request.subdomains.first)
    if @site.layout?
      self.class.layout(@site.layout_name)
    else
      self.class.layout('default_lay')
    end
  end
end
</code></pre>

<p>In this case, calling the <code>layout</code> method causes Rails to set the class instance variable <code>@_layout</code> for the controller class. If two concurrent requests (serve by two threads) hit this code simultaneously, they might end up in a race condition and overwrite each others’ layout.</p>

<p>In this case, the correct way to set the layout is to use a symbol with the layout call:</p>

<pre><code class="ruby">class HomeController &lt; ApplicationController
  before_filter :set_site
  layout :site_layout

  def index
  end

  private

  def set_site
    @site = Site.find_by_subdomain(request.subdomains.first)
  end

  def site_layout
    if @site.layout?
      @site.layout_name
    else
      'default_lay'
    end
  end
end
</code></pre>

<p>However, this is besides the point. The point is, you might end up using class variables and class instance variables by accident, thus making your app thread-unsafe.</p>

<h3>Memoization</h3>

<p>Memoization is a technique where you lazily set a variable if it is not already set. It is a common technique used where the original functionality is at least moderately expensive and the resulting variable is used several times within a request.</p>

<p>A common case would be to set the current user in a controller:</p>

<pre><code class="ruby">class SekritController &lt; ApplicationController
  before_filter :set_user

  private

  def set_user
    @current_user ||= User.find(session[:user_id])
  end
end
</code></pre>

<p>Memoization can be an issue for thread safety for a couple of reasons:</p>

<ul>
<li>It is often used to store data in class variables or class instance variables (see above).</li>
<li>The <code>||=</code> operator is in fact two operations, so there is a potential context switch happening in the middle of it, causing a race condition between threads.</li>
</ul>


<p>It would be easy to dismiss memoization as the cause of the issue, and tell people just to avoid class variables and class instance variables. However, the issue is more complex than that.</p>

<p>In <a href="https://github.com/rails/rails/pull/9789">this issue</a>, Evan Phoenix squashes a really tricky race condition bug in the Rails codebase caused by calling <code>super</code> in a memoization function. So even though you would only be using instance variables, you might end up with race conditions with memoization.</p>

<p>What’s a developer to do, then?</p>

<ul>
<li>Make sure memoization makes sense and a difference in your case. In many cases Rails actually caches the result anyway, so that you are not saving a whole lot if any resources with your memoization method.</li>
<li>Don’t memoize to class variables or class instance variables. If you need to memoize something on the class level, use thread local variables (<code>Thread.current[:baz]</code>) instead. Be aware, though, that it is still kind of a global variable. So while it&rsquo;s thread-safe, it still might not be good coding practice.</li>
</ul>


<pre><code class="ruby">def set_expensive_var
  Thread.current[:expensive_var] ||= MyModel.find(session[:goo_id])
end
</code></pre>

<ul>
<li><p>If you absolutely think you must be able to share the result across threads, use a <a href="http://lucaguidi.com/2014/03/27/thread-safety-with-ruby.html">mutex</a> to synchronize the memoizing part of your code. Keep in mind, though, that you’re kinda breaking the Shared nothing model of Rails with that. It’s kind of a half-assed sharing method anyway, since it only works across threads, not across processes.</p>

<p>Also keep in mind, that a mutex only saves you from race conditions inside itself. So it doesn&rsquo;t help you a whole lot with class variables unless you put the lock around the whole controller action, which was exactly what we wanted to avoid in the first place.</p></li>
</ul>


<pre><code class="ruby">class GooController &lt; ApplicationController
  @@lock = Mutex.new
  before_filter :set_expensive_var

  private

  def set_expensive_var
    @@lock.synchronize do
      @@stupid_class_var ||= Foo.bar(params[:subdomain])
    end
  end
end
</code></pre>

<ul>
<li>Use different instance variable names when you use inheritance and <code>super</code> in memoization methods.</li>
</ul>


<pre><code class="ruby">class Foo
  def env_config
    @env_config ||= {foo: 'foo', bar: 'bar'}
  end
end

class Bar &lt; Foo
  def env_config
    @bar_env_config ||= super.merge({foo: 'baz'})
  end
end
</code></pre>

<h3>Constants</h3>

<p>Yes, constants. <em>You didn’t believe constants are really constant in Ruby, did you?</em> Well, they kinda are:</p>

<pre><code class="bash">irb(main):008:0&gt; CON
=&gt; [1]
irb(main):009:0&gt; CON = [1,2]
(irb):9: warning: already initialized constant CON
</code></pre>

<p>So you do get a warning when trying to reassign a constant, but the reassignment still goes through. That’s not the real problem, though. The real issue is that the constancy of constants only applies to the object reference, not the referenced object. And if the referenced object can be mutated, you have a problem.</p>

<p>Yeah, you remember right. <em>All the core data structures in Ruby are mutable</em>.</p>

<pre><code class="bash">irb(main):010:0&gt; CON
=&gt; [1, 2]
irb(main):011:0&gt; CON &lt;&lt; 3
=&gt; [1, 2, 3]
irb(main):012:0&gt; CON
=&gt; [1, 2, 3]
</code></pre>

<p>Of course, you should never, ever do this. And few will. There’s a catch, however. Since Ruby variable assignments also use references, you might end up mutating a constant by accident.</p>

<pre><code class="bash">irb(main):010:0&gt; CON
=&gt; [1, 2]
irb(main):011:0&gt; arr = CON
=&gt; [1, 2]
irb(main):012:0&gt; arr &lt;&lt; 3
=&gt; [1, 2, 3]
irb(main):013:0&gt; CON
=&gt; [1, 2, 3]
</code></pre>

<p>If you want to be sure that your constants are never mutated, <a href="http://www.informit.com/articles/article.aspx?p=2251208&amp;seqNum=4">you can freeze</a> them upon creation:</p>

<pre><code class="bash">irb(main):001:0&gt; CON = [1,2,3].freeze
=&gt; [1, 2, 3]
irb(main):002:0&gt; CON &lt;&lt; 4
RuntimeError: can't modify frozen Array
  from (irb):2
  from /Users/jarkko/.rbenv/versions/2.1.2/bin/irb:11:in `&lt;main&gt;'
</code></pre>

<p>Keep in mind, though, that freeze is shallow. It only applies to the actual <code>Array</code> object in this case, not its items.</p>

<h3>Environment variables</h3>

<p><code>ENV</code> is really just a hash-like construct referenced by a constant. Thus, everything that applies to constants above, also applies to it.</p>

<pre><code class="ruby">ENV['version'] = "1.2" # Don't do this
</code></pre>

<h2>Making sure 3rd party code is thread-safe</h2>

<p>If you want your app to be thread-safe, all the third-party code it uses also needs to be thread-safe in the context of your app.</p>

<p>The first thing you probably should do with any gem is to read through its documentation and Google for whether it is deemed thread-safe. That said, even if it were, there’s no escaping double-checking yourself. Yes, by reading through the source code.</p>

<p>As a general rule, all that I wrote above about making your own code thread-safe applies here as well. However…</p>

<p><strong>With 3rd party gems and Rails plugins, context matters.</strong></p>

<p>If the third party code you use is just a library that your own code calls, you’re fairly safe (considering you’re using it in a thread-safe way yourself). It can be thread-unsafe just the same way as <code>Array</code> is, but if you don’t share the structures between threads, you’re more or less fine.</p>

<p>However, many Rails plugins actually extend or modify the Rails classes, in which case all bets are off. In this case, you need to scrutinize the library code much, much more thoroughly.</p>

<p>So how do you know which type of the two above a gem or plugin is? Well, you don’t. Until you read the code, that is. But you are reading the code anyway, aren’t you?</p>

<h3>What smells to look for in third party code?</h3>

<p>Everything we mentioned above regarding your own code applies.</p>

<ul>
<li>Class variables (<code>@@foo</code>)</li>
<li>Class instance variables (<code>@bar</code>, trickier to find since they look the same as any old ivar)</li>
<li>Constants, ENV variables, and potential variables through which they can be mutated.</li>
<li>Memoization, especially when one of the two above points are involved</li>
<li>Creation of new threads (<code>Thread.new</code>, <code>Thread.start</code>). These obviously aren’t smells just by themselves. However, the risks mentioned above only materialize when shared across threads, so you should at least be familiar with in which cases the library is spawning new threads.</li>
</ul>


<p>Again, context matters. Nothing above alone makes code thread-unsafe. Even sharing data with them doesn’t. But modifying that data does. So pay close attention to whether the libs provide methods that can be used to modify shared data.</p>

<h2>The final bad news</h2>

<p>No matter how thoroughly you read through the code in your application and the gems it uses, you cannot be 100% sure that the whole is thread-safe. Heck, even running and profiling the code in a test environment might not reveal lingering thread safety issues.</p>

<p>This is because many race conditions only appear under serious, concurrent load. That’s why you should both try to squash them from the code and keep a close eye on your production environment on a continual basis. Your app being perfectly thread-safe today does not guarantee the same is true a couple of sprints later.</p>

<h2>Recap</h2>

<p>To make a Rails app thread-safe, you have to make sure the code is thread-safe on three different levels:</p>

<ul>
<li>Rails framework and its dependencies.</li>
<li>Your app code.</li>
<li>Any third party code you use.</li>
</ul>


<p>The first one of these is handled for you, unless you do stupid shit with it (like the memoization example above). The rest is your responsibility.</p>

<p>The main thing to keep in mind is to never mutate data that is shared across threads. Most often this happens through class variables, class instance variables, or by accidentally mutating objects that are referenced by a constant.</p>

<p>There are, however, some pretty esoteric ways an app can end up thread-unsafe, so be prepared to track down and fix the last remaining threading issues while running in production.</p>

<p>Have fun!</p>

<p><em><strong>Acknowledgments</strong>: Thanks to <a href="https://twitter.com/raggi">James Tucker</a>, <a href="https://twitter.com/evanphx">Evan Phoenix</a>, and the whole <a href="https://bearmetal.eu/team/">Bear Metal gang</a> for providing feedback for the drafts of this article.</em></p>

<h3>Related articles</h3>

<p><em>This article is a part of a series about Rails performance optimization and GC tuning. Other articles in the series:</em></p>

<ul>
<li><a href="https://bearmetal.eu/theden/rails-garbage-collection-tuning-approaches/">Rails Garbage Collection: Tuning Approaches</a></li>
<li><a href="https://bearmetal.eu/theden/rails-garbage-collection-naive-defaults/">Rails Garbage Collection: Naive Defaults</a></li>
<li><a href="https://bearmetal.eu/theden/does-rails-scale/">Does Rails Scale?</a></li>
<li><a href="https://bearmetal.eu/theden/rails-garbage-collection-age-matters/">Rails Garbage Collection: Age Matters</a></li>
<li><a href="https://bearmetal.eu/theden/help-my-rails-app-is-melting-under-the-launch-day-load/">Help! My Rails App Is Melting Under the Launch Day Load</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rails Garbage Collection: Tuning Approaches]]></title>
    <link href="https://bearmetal.eu/theden/rails-garbage-collection-tuning-approaches/"/>
    <updated>2015-02-20T09:19:02+02:00</updated>
    <id>https://bearmetal.eu/theden/rails-garbage-collection-tuning-approaches</id>
    <content type="html"><![CDATA[<p><em>MRI maintainers have put a tremendous amount of work into improving the garbage collector in Ruby 2.0 through 2.2. The engine has thus gained a lot more horsepower. However, it&rsquo;s still not trivial to get the most out of it. In this post we&rsquo;re going to gain a better understanding of how and what to tune for.</em></p>

<p><figure markdown="1">
  <a href="https://www.flickr.com/photos/stevoarnold/2862901152">
    <img src="https://farm3.staticflickr.com/2218/2862901152_b6b39592bd_o_d.jpg">
  </a></p>

<p>  <figcaption>
    <p>
      Photo by <a href="https://www.flickr.com/photos/stevoarnold/2862901152">Steve Arnold</a>, used under a Creative Commons license.
    </p>
  </figcaption>
</figure></p>

<p>Koichi Sasada (_ko1, Ruby MRI maintainer) famously mentioned in a <a href="http://www.atdot.net/~ko1/activities/2014_rubyconf_ph_pub.pdf">presentation (slide 89)</a>:</p>

<blockquote><p> <strong>Try GC parameters</strong></p>

<ul>
<li>There is no silver bullet

<ul>
<li>No one answer for all applications</li>
<li>You should not believe other applications settings easily</li>
</ul>
</li>
<li>Try and try and try!</li>
</ul>
</blockquote>

<p>This is true in theory but a <em>whole lot harder</em> to pull off in practice due to three primary problems:</p>

<ul>
<li>Interpreter GC semantics and configuration change over time.</li>
<li>One GC config isn&rsquo;t optimal for all app runtime contexts: tests, requests, background jobs, rake tasks, etc.</li>
<li>During the lifetime and development cycles of a project, it&rsquo;s very likely that existing GC settings are invalidated quickly.</li>
</ul>


<h3>An evolving Garbage Collector</h3>

<p>The garbage collector has frequently changed in the latest MRI Ruby releases. The changes have also broken many existing assumptions and environment variables that tune the GC. Compare <code>GC.stat</code> on Ruby 2.1:</p>

<pre><code class="ruby">{ :count=&gt;7, :heap_used=&gt;66, :heap_length=&gt;66, :heap_increment=&gt;0,
  :heap_live_slot=&gt;26397, :heap_free_slot=&gt;507, :heap_final_slot=&gt;0,
  :heap_swept_slot=&gt;10698, :heap_eden_page_length=&gt;66, :heap_tomb_page_length=&gt;0,
  :total_allocated_object=&gt;75494, :total_freed_object=&gt;49097,
  :malloc_increase=&gt;465840, :malloc_limit=&gt;16777216, :minor_gc_count=&gt;5,
  :major_gc_count=&gt;2, :remembered_shady_object=&gt;175,
  :remembered_shady_object_limit=&gt;322, :old_object=&gt;9109, :old_object_limit=&gt;15116,
  :oldmalloc_increase=&gt;1136080, :oldmalloc_limit=&gt;16777216 }
</code></pre>

<p>…with Ruby 2.2:</p>

<pre><code class="ruby">{ :count=&gt;6, :heap_allocated_pages=&gt;74, :heap_sorted_length=&gt;75,
  :heap_allocatable_pages=&gt;0, :heap_available_slots=&gt;30162, :heap_live_slots=&gt;29729,
  :heap_free_slots=&gt;433, :heap_final_slots=&gt;0, :heap_marked_slots=&gt;14752,
  :heap_swept_slots=&gt;11520, :heap_eden_pages=&gt;74, :heap_tomb_pages=&gt;0,
  :total_allocated_pages=&gt;74, :total_freed_pages=&gt;0,
  :total_allocated_objects=&gt;76976, :total_freed_objects=&gt;47247,
  :malloc_increase_bytes=&gt;449520, :malloc_increase_bytes_limit=&gt;16777216,
  :minor_gc_count=&gt;4, :major_gc_count=&gt;2, :remembered_wb_unprotected_objects=&gt;169,
  :remembered_wb_unprotected_objects_limit=&gt;278, :old_objects=&gt;9337,
  :old_objects_limit=&gt;10806, :oldmalloc_increase_bytes=&gt;1147760,
  :oldmalloc_increase_bytes_limit=&gt;16777216 }
</code></pre>

<p>In Ruby 2.2 we can see a lot more to introspect and tune, but this also comes with a steep learning curve which is (and should be) out of scope for most developers.</p>

<h3>One codebase, different roles</h3>

<p>A modern Rails application is typically used day to day in different contexts:</p>

<ul>
<li>Running tests</li>
<li>rake tasks</li>
<li>database migrations</li>
<li>background jobs</li>
</ul>


<p>They all start pretty much the same way with the VM compiling code to instruction sequences. Different roles affect the Ruby heap and the garbage collector in very different ways, however.</p>

<p>This job typically runs for 13 minutes, triggers 133 GC cycles and allocates a metric ton of objects. Allocations are very bursty and in batches.</p>

<pre><code class="ruby">class CartCleanupJob &lt; ActiveJob::Base
  queue_as :default

  def perform(*args)
    Cart.cleanup(Time.now)
  end
end
</code></pre>

<p>This controller action allocates 24 555 objects. Allocator throughput isn&rsquo;t very variable.</p>

<pre><code class="ruby">class CartsController &lt; ApplicationController
  def show
    @cart = Cart.find(params[:id])
  end
end
</code></pre>

<p>Our test case contributes 175 objects to the heap. Test cases generally are very variable and bursty in allocation patterns.</p>

<pre><code class="ruby">def test_add_to_cart
  cart = carts(:empty)
  cart &lt;&lt; products(:butter)
  assert_equal 1, cart.items.size
end
</code></pre>

<p>The default GC behavior isn&rsquo;t optimal for all of these execution paths within the same project and neither is <a href="http://www.reddit.com/r/ruby/comments/2m663d/ruby_21_gc_settings">throwing</a> a single set of <code>RUBY_GC_*</code> environment variables at it.</p>

<p>We&rsquo;d like to refer to processing in these different contexts as &ldquo;units of work&rdquo;.</p>

<h3>Fast development cycles</h3>

<p>During the lifetime and development cycle of a project, it&rsquo;s very likely that garbage collector settings that were valid yesterday aren&rsquo;t optimal anymore after the next two sprints. Changes to your Gemfile, rolling out new features, and bumping the Ruby interpreter all affect the garbage collector.</p>

<pre><code class="ruby">source 'https://rubygems.org'

ruby '2.2.0' # Invalidates most existing RUBY_GC_* variables

gem 'mail' # slots galore
</code></pre>

<h2>Process lifecycle events</h2>

<p>Let&rsquo;s have a look at a few events that are important during the lifetime of a process. They help the tuner to gain valuable insights into how well the garbage collector is working and how to further optimize it. They all hint at how the heap changes and what triggered a GC cycle.</p>

<p>How many mutations happened for example while</p>

<ul>
<li>processing a request</li>
<li>between booting the app and processing a request</li>
<li>during the lifetime of the application?</li>
</ul>


<h3>When it booted</h3>

<p><em>When the application is ready to start doing work.</em> For Rails application, this is typically when the app has been fully loaded in production, ready to serve requests, ready to accept background work, etc. All source files have been loaded and most resources acquired.</p>

<h3>When processing started</h3>

<p><em>At the start of a unit of work.</em> Typically the start of an HTTP request, when a background job has been popped off a queue, the start of a test case or any other type of processing that is the primary purpose of running the process.</p>

<h3>When processing ended</h3>

<p><em>At the end of a unit of work.</em> Typically the end of a HTTP request, when a background job has finished processing, the end of a test case or any other type of processing that is the primary purpose of running the process.</p>

<h3>When it terminated</h3>

<p>Triggered when the application terminates.</p>

<h2>Knowing when and why GC happens</h2>

<p>Tracking GC cycles interleaved with the aforementioned application events yield insights into why a particular GC cycle happens. The progression from BOOTED to TERMINATED and everything else is important because mutations that happen during the fifth HTTP request of a new Rails process also contribute to a GC cycle during request number eight.</p>

<h2>On tuning</h2>

<p>Primarily the garbage collector exposes tuning variables in these three categories:</p>

<ul>
<li>Heap slot values: where Ruby objects live</li>
<li>Malloc limits: off heap storage for large strings, arrays and other structures</li>
<li>Growth factors: by how much to grow slots, malloc limits etc.</li>
</ul>


<p>Tuning GC parameters is generally a tradeoff between tuning for speed (thus using more memory) and tuning for low memory usage while giving up speed. We think it&rsquo;s possible to infer a reasonable set of defaults from observing the application at runtime that&rsquo;s conservative with memory, yet maintain reasonable throughput.</p>

<h2>A solution</h2>

<p>We&rsquo;ve been working on a product, <a href="https://tunemygc.com">TuneMyGC</a> for a few weeks that attempts to do just that. Our goals and objectives are:</p>

<ul>
<li>A repeatable and systematic tuning process that respects fast development cycles</li>
<li>It should have awareness of runtime profiles being different for HTTP requests, background job processing etc.</li>
<li>It should support current mainline Ruby versions without developers having to keep up to date with changes</li>
<li>Deliver reasonable memory footprints with better runtime performance</li>
<li>Provide better insights into GC characteristics both for app owners and possibly also ruby-core</li>
</ul>


<p>Here&rsquo;s an example of <a href="http://www.discourse.org">Discourse</a> being automatically tuned for better 99th percentile throughput. Response times in milliseconds, 200 requests:</p>

<table>
<thead>
<tr>
<th> <em>Controller</em>  </th>
<th> <em><a href="https://tunemygc.com/configs/c5214cfa00b3bf429badd2161c4b6a08">GC defaults</a></em> </th>
<th> <em><a href="https://tunemygc.com/configs/e129791f94159a8c75bef3a636c05798">Tuned GC</a></em> </th>
</tr>
</thead>
<tbody>
<tr>
<td> categories  </td>
<td>     227      </td>
<td>    160         </td>
</tr>
<tr>
<td> home        </td>
<td>     163      </td>
<td>    113         </td>
</tr>
<tr>
<td> topic       </td>
<td>     55       </td>
<td>    40          </td>
</tr>
<tr>
<td> user        </td>
<td>     92       </td>
<td>    76          </td>
</tr>
</tbody>
</table>


<h4><a href="https://tunemygc.com/configs/c5214cfa00b3bf429badd2161c4b6a08">GC defaults</a>:</h4>

<pre><code class="bash">$ RUBY_GC_TUNE=1 RUBY_GC_TOKEN=a5a672761b25265ec62a1140e21fc81f ruby script/bench.rb -m -i 200
</code></pre>

<p>Raw GC stats from Discourse&rsquo;s bench.rb script:</p>

<pre><code class="bash ">GC STATS:
count: 106
heap_allocated_pages: 2447
heap_sorted_length: 2455
heap_allocatable_pages: 95
heap_available_slots: 997407
heap_live_slots: 464541
heap_free_slots: 532866
heap_final_slots: 0
heap_marked_slots: 464530
heap_swept_slots: 532876
heap_eden_pages: 2352
heap_tomb_pages: 95
total_allocated_pages: 2447
total_freed_pages: 0
total_allocated_objects: 27169276
total_freed_objects: 26704735
malloc_increase_bytes: 4352
malloc_increase_bytes_limit: 16777216
minor_gc_count: 91
major_gc_count: 15
remembered_wb_unprotected_objects: 11669
remembered_wb_unprotected_objects_limit: 23338
old_objects: 435435
old_objects_limit: 870870
oldmalloc_increase_bytes: 4736
oldmalloc_increase_bytes_limit: 30286118 
</code></pre>

<h3><a href="https://tunemygc.com/configs/e129791f94159a8c75bef3a636c05798">TuneMyGC recommendations</a></h3>

<pre><code class="bash">$ RUBY_GC_TUNE=1 RUBY_GC_TOKEN=a5a672761b25265ec62a1140e21fc81f RUBY_GC_HEAP_INIT_SLOTS=997339 RUBY_GC_HEAP_FREE_SLOTS=626600 RUBY_GC_HEAP_GROWTH_FACTOR=1.03 RUBY_GC_HEAP_GROWTH_MAX_SLOTS=88792 RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR=2.4 RUBY_GC_MALLOC_LIMIT=34393793 RUBY_GC_MALLOC_LIMIT_MAX=41272552 RUBY_GC_MALLOC_LIMIT_GROWTH_FACTOR=1.32 RUBY_GC_OLDMALLOC_LIMIT=39339204 RUBY_GC_OLDMALLOC_LIMIT_MAX=47207045 RUBY_GC_OLDMALLOC_LIMIT_GROWTH_FACTOR=1.2 ruby script/bench.rb -m -i 200
</code></pre>

<p>Raw GC stats from Discourse&rsquo;s bench.rb script:</p>

<pre><code class="bash">GC STATS:
count: 44
heap_allocated_pages: 2893
heap_sorted_length: 2953
heap_allocatable_pages: 161
heap_available_slots: 1179182
heap_live_slots: 460935
heap_free_slots: 718247
heap_final_slots: 0
heap_marked_slots: 460925
heap_swept_slots: 718277
heap_eden_pages: 2732
heap_tomb_pages: 161
total_allocated_pages: 2893
total_freed_pages: 0
total_allocated_objects: 27167493
total_freed_objects: 26706558
malloc_increase_bytes: 4352
malloc_increase_bytes_limit: 34393793
minor_gc_count: 34
major_gc_count: 10
remembered_wb_unprotected_objects: 11659
remembered_wb_unprotected_objects_limit: 27981
old_objects: 431838
old_objects_limit: 1036411
oldmalloc_increase_bytes: 4736
oldmalloc_increase_bytes_limit: 39339204
</code></pre>

<p>We can see a couple of interesting points here:</p>

<ul>
<li>There is much less GC activity – only 44 rounds instead of 106.</li>
<li>Slot buffers are still decent for high throughput. There are 718247 free slots (<code>heap_free_slots</code>) of 1179182 available slots (<code>heap_available_slots</code>), which is 64% of the current live objects (<code>heap_live_slots</code>). This value however is slightly skewed because the <a href="http://www.discourse.org">Discourse</a> benchmark script forces a major GC before dumping these stats - there are about as many swept slots as free slots (<code>heap_swept_slots</code>).</li>
<li>Malloc limits (<code>malloc_increase_bytes_limit</code> and <code>oldmalloc_increase_bytes_limit</code>) and growth factors (<code>old_objects_limit</code> and <code>remembered_wb_unprotected_objects_limit</code>) are in line with actual app usage. The TuneMyGC service considers when limits and growth factors are bumped during the app lifecycle and attempts to raise limits via environment variables slightly higher to prevent excessive GC activity.</li>
</ul>


<p>Now it&rsquo;s your turn.</p>

<h2>Feel free to take your Rails app for a spin too!</h2>

<h3>1. Add to your Gemfile.</h3>

<pre><code class="bash">gem 'tunemygc'
</code></pre>

<h3>2. Register your Rails application.</h3>

<pre><code class="bash">$ bundle exec tunemygc -r email@yourdomain.com
      Application registered. Use RUBY_GC_TOKEN=08de9e8822c847244b31290cedfc1d51 in your environment.
</code></pre>

<h3>3. Boot your app. We recommend an optimal GC configuration when it ends</h3>

<pre><code class="bash">$ RUBY_GC_TOKEN=08de9e8822c847244b31290cedfc1d51 RUBY_GC_TUNE=1 bundle exec rails s
</code></pre>

<h2>Related articles</h2>

<p><em>This article is a part of a series about Rails performance optimization and GC tuning. Other articles in the series:</em></p>

<ul>
<li><a href="https://bearmetal.eu/theden/rails-garbage-collection-naive-defaults/">Rails Garbage Collection: Naive Defaults</a></li>
<li><a href="https://bearmetal.eu/theden/does-rails-scale/">Does Rails Scale?</a></li>
<li><a href="https://bearmetal.eu/theden/rails-garbage-collection-age-matters/">Rails Garbage Collection: Age Matters</a></li>
<li><a href="https://bearmetal.eu/theden/help-my-rails-app-is-melting-under-the-launch-day-load/">Help! My Rails App Is Melting Under the Launch Day Load</a></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Help! My Rails App Is Melting Under the Launch Day Load]]></title>
    <link href="https://bearmetal.eu/theden/help-my-rails-app-is-melting-under-the-launch-day-load/"/>
    <updated>2015-01-12T13:39:00+02:00</updated>
    <id>https://bearmetal.eu/theden/help-my-rails-app-is-melting-under-the-launch-day-load</id>
    <content type="html"><![CDATA[<p><figure markdown="1">
  <a href="https://www.flickr.com/photos/pasukaru76/4484360302">
    <img src="https://farm5.staticflickr.com/4065/4484360302_70ac4b6a8d_o_d.jpg">
  </a></p>

<p>  <figcaption>
    <p>
      Photo by <a href="https://www.flickr.com/photos/pasukaru76/4484360302">Pascal</a>
    </p>
  </figcaption>
</figure></p>

<p>It was to be our day. The Finnish championship relay in orienteering was about to be held close to us, in a terrain type we knew inside and out. We had a great team, with both young guns and old champions. My friend Samuli had been fourth in the individual middle distance championships the day before. My only job was to handle the first leg securely and pass the baton to the more experienced and tougher guys who would then take care of our success. And I failed miserably.</p>

<p>My legs were like dough from the beginning. I was supposed to be in good shape, but I couldn&rsquo;t keep up with anyone. I was supposed to take it easy and orienteer cleanly, but I ran like a headless chicken, making a mistake after another. Although I wouldn&rsquo;t learn the term until years later, this was my crash course to <a href="http://en.wikipedia.org/wiki/Ego_depletion">ego depletion</a>.</p>

<hr />

<p>The day before the relay we organized the middle distance Finnish champs in my old hometown Parainen. For obvious reasons, I was the de facto webmaster of our club pages, which also hosted the result service. The site was running on OpenACS, a system running on TCL I had a year or so of work experience with. I was supposed to know it.</p>

<p>After the race was over, I headed back to my friend&rsquo;s place, opened up my laptop… only to find out that the local orienteering forums were ablaze with complaints about our results page being down. Crap.</p>

<p>After hours or hunting down the issue, getting help on the OpenACS IRC channel, serving the results from a static page meanwhile, I finally managed to fix the issue. The app wasn&rsquo;t running enough server processes to keep up with the load. And the most embarrassing thing was that <em>the load wasn&rsquo;t even that high</em> – from high dozens to hundreds of simultaneous users. I headed to bed with my head spinning, hoping to scramble up my self confidence for the next day&rsquo;s race (with well-known results).</p>

<p>What does this have to do with Ruby or Rails? Nothing, really. And yet everything. The point is that most of us have a similar story to share. It&rsquo;s much more common to have a meltdown story with a reasonably low number of users than actually have a slashdotting/hackernewsing/daring fireball hit your app. If you aren&rsquo;t old enough to have gone through something like this, you probably will. But you don&rsquo;t have to.</p>

<hr />

<p>During the dozen or so years since the aforementioned episode, I&rsquo;ve gone through some serious loads. Some of them we have handled badly, but most – including the <a href="http://wildfireapp.blogspot.fi/2009/04/wildfire-runs-facebook-site-governance.html">Facebook terms of service vote campaign</a> – with at least reasonable grace. This series of articles about Rails performance builds upon those war stories.</p>

<p>We have already posted a couple of articles to start off the series.</p>

<ol>
<li><a href="/theden/rails-garbage-collection-naive-defaults/">Rails Garbage Collection: Naive Defaults</a></li>
<li><a href="/theden/does-rails-scale/">Does Rails Scale?</a></li>
<li><a href="/theden/rails-garbage-collection-age-matters/">Rails Garbage Collection: Age Matters</a></li>
</ol>


<p>This article will serve as kind of a belated intro to the series, introducing our high level principles regarding the subject but without going more to the details.</p>

<h2>The Bear Metal ironclad rules of Rails performance</h2>

<h3>Scalability is not the same as performance</h3>

<p>As I already noted in <a href="/theden/does-rails-scale/">Does Rails Scale?</a>, it&rsquo;s worth pointing out that performance is not the same thing as scalability. They are related for sure. But you can perform similarly poorly from your first to your millionth user and be “scalable”. There is also the difference that performance is right here and now. If your app scales well, you can just throw more hardware (virtual or real) at the problem and solve it by that.</p>

<p>The good news is that Rails scales quite well out of the box for the vast majority of real-world needs. You probably won&rsquo;t be the next Twitter or even Basecamp. In your dreams and VC prospectus maybe, but let&rsquo;s be honest, the odds are stacked against you. So don&rsquo;t sweat about that too much.</p>

<p>Meanwhile, you do want your app to perform well enough for your initial wave of users.</p>

<h3>Perceived performance is what matters</h3>

<p>There are basically three different layers of performance for any web app: the server level (I&rsquo;m bundling everything from the data store to the frontend server here), browser rendering and the performance perceived by the user. The two latter ones are very close to each other but not exactly the same. You can tweak the perceived performance with tricks on the UI level, something that often isn&rsquo;t even considered performance.</p>

<p>The most important lesson here is that the perceived performance is what matters. It makes no difference what your synthetic performance tests on your server say if the UI of the app feels sluggish. There is no panacea to solve this, but make no mistake, it is what matters when the chicken come home to roost.</p>

<h3>Start with quick, large, and obvious wins</h3>

<p>The fact is that even a modest amount of users can make your app painfully slow. The good thing is that you can probably fix that just with hitting the low-hanging fruit. You won&rsquo;t believe how many Rails apps reveal that they&rsquo;re running in the development mode even in production by – when an error occurs – leaking the whole error trace out to the end user.</p>

<p>Other examples of issues that are fairly easy to spot and fix are N+1 query issues with ActiveRecord associations, missing database indeces, and running a single, non-concurrent app server instance, where any longer-running action will block the whole app from other users.</p>

<h3>YAGNI</h3>

<p>Once you have squashed all the low-hanging fruit with your metal-reinforced bat, relax. Tuning app performance shouldn&rsquo;t be your top priority at the moment – unless it is, but in that case you will know for sure. What you should be focusing on is how to get paying customers and how you can make them kick ass. If you have clear performance issues, by all means fix them. However…</p>

<h3>Don&rsquo;t assume, measure</h3>

<p>You probably don&rsquo;t have any idea how many users your app needs to support from the get go. That&rsquo;s fine. The reality will teach you. As long as you don&rsquo;t royally fuck up the share nothing (and 12 factor if you&rsquo;re on a cloud platform such as Heroku) architecture, you should be able to react to issues quickly.</p>

<p>That said, you probably do want to do some baseline load testing with your app if you&rsquo;re opening for a much larger private group or the public. The good news is that it is very cheap to spin up a virtual server instance just for a couple of hours and hit your app hard with it. Heck, you can handle the baseline from your laptop if needed. With that you should be able to get over the initial, frightening launch.</p>

<p>Once your app is up and running under load from real users, your tuning work starts for real. Only now will you be able to measure where the real hot paths and bottlenecks in your app are, based on real usage data, not just assumptions. At this point you&rsquo;ll have a plethora of tools at your disposal, from the good old <a href="https://github.com/wvanbergen/request-log-analyzer">request log analyzer</a> to commercial offerings such as <a href="https://www.skylight.io">Skylight</a>, and <a href="http://newrelic.com">New Relic</a>.</p>

<p>On the frontend most browsers have nowadays developer tools to optimize end-user performance, from Chrome and Safari&rsquo;s built-in developer tools to <a href="http://getfirebug.com">Firebug</a> for Firefox.</p>

<h2>Wrap-up</h2>

<p>In this introductory article to building performant Rails (or any, for that matter) web apps, we took a look at five basic rules of performance optimization:</p>

<ol>
<li>Scalability is not the same as performance.</li>
<li>Perceived performance is what matters.</li>
<li>Start with the low-hanging fruit.</li>
<li>YAGNI</li>
<li>Don&rsquo;t assume, measure.</li>
</ol>


<p>We will get (much) more in the details of Rails performance optimization in later articles. At that point we&rsquo;ll enter a territory where one size does not fit all anymore. However, whatever your particular performance problem is, you should keep the five rules above at the top your mind.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rails Garbage Collection: Age Matters]]></title>
    <link href="https://bearmetal.eu/theden/rails-garbage-collection-age-matters/"/>
    <updated>2014-12-22T20:26:00+02:00</updated>
    <id>https://bearmetal.eu/theden/rails-garbage-collection-age-matters</id>
    <content type="html"><![CDATA[<p>In a <a href="https://bearmetal.eu/theden/rails-garbage-collection-naive-defaults/">previous post</a> in the <a href="/theden/categories/rails-performance">Rails Performance</a> series we stated that the default garbage collection settings for <a href="http://www.rubyonrails.org">Ruby on Rails</a> applications are not optimal. In this post we&rsquo;ll explore the basics of object age in RGenGC, Ruby 2.1&rsquo;s new <em>restricted generational garbage collector</em>.</p>

<p>As a prerequisite of this and subsequent posts, basic understanding of a <em>mark and sweep</em><sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup> collector is assumed.</p>

<p><img src="/images/gc_mark_sweep.png" alt="" /></p>

<p>A somewhat simplified mark and sweep cycle goes like this:</p>

<ol>
<li>A mark and sweep collector traverses the object graph.</li>
<li>It checks which objects are in use (referenced) and which ones are not.</li>
<li>This is called object marking, aka. the <strong>MARK PHASE</strong>.</li>
<li>All unused objects are freed, making their memory available.</li>
<li>This is called sweeping, aka. the <strong>SWEEP PHASE</strong>.</li>
<li>Nothing changes for used objects.</li>
</ol>


<p>A GC cycle prior to Ruby 2.1 works like that. A typical Rails app boots with 300 000 live objects of which all need to be scanned during the <strong>MARK</strong> phase. That usually yields a smaller set to <strong>SWEEP</strong>.</p>

<p>A large percentage of the graph is going to be traversed over and over again but will never be reclaimed. This is not only CPU intensive during GC cycles, but also incurs memory overhead for accounting and anticipation for future growth.</p>

<h2>Old and young objects</h2>

<p><strong>What generally makes an object old?</strong></p>

<ul>
<li><em>All new objects are considered to be young</em>.</li>
<li><em>Old objects survived at least one GC cycle (major or minor)</em> The collector thus reasons that the object will stick around and not become garbage quickly.</li>
</ul>


<p>The idea behind the new generational garbage collector is this:</p>

<blockquote><p><strong>MOST OBJECTS DIE YOUNG.</strong></p></blockquote>

<p>To take advantage of this fact, the new GC classifies objects on the Ruby heap as either <strong>OLD</strong> or <strong>YOUNG</strong>. This segregation now allows the garbage collector to work with two distinct generations, with the <strong>OLD</strong> generation much less likely to yield much improvement towards recovering memory.</p>

<p>For a typical Rails request, some examples of old and new objects would be:</p>

<ul>
<li><strong>Old:</strong> compiled routes, templates, ActiveRecord connections, cached DB column info, classes, modules etc.</li>
<li><strong>New:</strong> short lived strings within a partial, a string column value from an ActiveRecord result, a coerced DateTime instance etc.</li>
</ul>


<p>Young objects are more likely to reference old objects than old objects referencing young objects. Old objects also frequently reference other old objects.</p>

<pre><code class="ruby">  u = User.first
  #&lt;User id: 1, email: "lourens@something.com", encrypted_password: "blahblah...", reset_password_token: nil, reset_password_sent_at: nil, remember_created_at: nil, sign_in_count: 2, current_sign_in_at: "2014-10-31 11:52:30", last_sign_in_at: "2014-10-29 10:04:01", current_sign_in_ip: "127.0.0.1", last_sign_in_ip: "127.0.0.1", created_at: "2014-10-29 10:04:01", updated_at: "2014-11-30 14:07:15", provider: nil, uid: nil, first_name: "dfdsfds", last_name: "dfdsfds", confirmation_token: nil, confirmed_at: "2014-10-30 10:11:42", confirmation_sent_at: nil, unconfirmed_email: nil, onboarded_at: nil&gt;
</code></pre>

<p>Notice how the transient attribute keys and names reference the long lived columns here:</p>

<pre><code class="ruby">    {"id"=&gt;
       #&lt;ActiveRecord::ConnectionAdapters::PostgreSQLAdapter::OID::Integer:0x007fbe756d1d30&gt;,
      "email"=&gt;
       #&lt;ActiveRecord::ConnectionAdapters::PostgreSQLAdapter::OID::Identity:0x007fbe756d1718&gt;,
      "encrypted_password"=&gt;
       #&lt;ActiveRecord::ConnectionAdapters::PostgreSQLAdapter::OID::Identity:0x007fbe756d1718&gt;,
      "reset_password_token"=&gt;
       #&lt;ActiveRecord::ConnectionAdapters::PostgreSQLAdapter::OID::Identity:0x007fbe756d1718&gt;,
      "reset_password_sent_at"=&gt;
       #&lt;ActiveRecord::AttributeMethods::TimeZoneConversion::Type:0x007fbe741f63c0
        @column=
         #&lt;ActiveRecord::ConnectionAdapters::PostgreSQLAdapter::OID::Timestamp:0x007fbe756d0e58&gt;&gt;,
</code></pre>

<p>Age segregation is also just a classification &ndash; old and young objects aren&rsquo;t stored in distinct memory spaces &ndash; they&rsquo;re just conceptional buckets. The generation of an object refers to the amount of GC cycles it survived:</p>

<pre><code class="ruby">irb(main):009:0&gt; ObjectSpace.dump([])
=&gt; "{\"address\":\"0x007fd24c007668\", \"type\":\"ARRAY\", \"class\":\"0x007fd24b872038\", \"length\":0, \"file\":\"(irb)\", \"line\":9, \"method\":\"irb_binding\", \"generation\":8, \"flags\":{\"wb_protected\":true}}\n"
irb(main):010:0&gt; GC.count
=&gt; 8
</code></pre>

<h2>What the heck is major and minor GC?</h2>

<p>You may have heard, read about or noticed in GC.stat output the terms &ldquo;minor&rdquo; and &ldquo;major&rdquo; GC.</p>

<pre><code class="ruby">    irb(main):003:0&gt; pp GC.stat
    {:count=&gt;32,
     :heap_used=&gt;1181,
     :heap_length=&gt;1233,
     :heap_increment=&gt;50,
     :heap_live_slot=&gt;325148,
     :heap_free_slot=&gt;156231,
     :heap_final_slot=&gt;0,
     :heap_swept_slot=&gt;163121,
     :heap_eden_page_length=&gt;1171,
     :heap_tomb_page_length=&gt;10,
     :total_allocated_object=&gt;2050551,
     :total_freed_object=&gt;1725403,
     :malloc_increase=&gt;1462784,
     :malloc_limit=&gt;24750208,
     :minor_gc_count=&gt;26,
     :major_gc_count=&gt;6,
     :remembered_shady_object=&gt;3877,
     :remembered_shady_object_limit=&gt;4042,
     :old_object=&gt;304270,
     :old_object_limit=&gt;259974,
     :oldmalloc_increase=&gt;23639792,
     :oldmalloc_limit=&gt;24159190}
</code></pre>

<p><strong>Minor GC (or &ldquo;partial marking&rdquo;):</strong> This cycle only traverses the young generation and is very fast. Based on the hypothesis that most objects die young, this GC cycle is thus the most effective at reclaiming back a large ratio of memory in proportion to objects traversed.</p>

<p>It runs quite often - 26 times for the GC dump of a booted Rails app above.</p>

<p><strong>Major GC:</strong> Triggered by out-of-memory conditions - Ruby heap space needs to be expanded (not OOM killer! :-)) Both old and young objects are traversed and it&rsquo;s thus significantly slower than a minor GC round. Generally when there&rsquo;s a significant increase in old objects, a major GC would be triggered. Every major GC cycle that an object survived bumps its current generation.</p>

<p>It runs much less frequently - six times for the stats dump above.</p>

<p>The following diagram represents a minor GC cycle (<strong>MARK</strong> phase completed, <strong>SWEEP</strong> still pending) that identifies and promotes some objects to old.</p>

<p><img src="/images/gc_first_minor.png" alt="" /></p>

<p>A subsequent minor GC cycle (<strong>MARK</strong> phase completed, <strong>SWEEP</strong> still pending) ignores old objects during the mark phase.</p>

<p><img src="/images/gc_second_minor.png" alt="" /></p>

<p>Most of the reclaiming efforts are thus focussed on the young generation (new objects). Generally 95% of objects are dead by the first GC. The current generation of an object is the number of major GC cycles it has survived.</p>

<h2>RGenGC</h2>

<p>At a very high level C Ruby 2.1&rsquo;s collector has the following properties:</p>

<ul>
<li>High throughput - it can sustain a high rate of allocations / collections due to faster minor GC cycles and very rare major GC cycles.</li>
<li>GC pauses are still long (&ldquo;stop the world&rdquo;) for major GC cycles.</li>
<li>Generational collectors have much shorter mark cycles as they traverse only the young generation, most of the time.</li>
</ul>


<p>This is a marked improvement to the C Ruby GC and serves as a base for implementing other advanced features moving forward. Ruby 2.2 supports incremental GC and object ages beyond just old and new definitions. A major GC cycle in 2.1 still runs in a &ldquo;stop the world&rdquo; manner, whereas a more involved incremental implementation (Ruby 2.2) interleaves short steps of mark and sweep cycles between other VM operations.</p>

<h2>Object references</h2>

<p>In this simple example below we create a String array with three elements.</p>

<pre><code class="ruby">    irb(main):001:0&gt; require 'objspace'
    =&gt; true
    irb(main):002:0&gt; ObjectSpace.trace_object_allocations_start
    =&gt; nil
    irb(main):003:0&gt; ary = %w(a b c)
    =&gt; ["a", "b", "c"]
</code></pre>

<p>Very much like a river flowing downstream, the array has knowledge of (a reference to) each of its String elements. On the contrary, the strings don&rsquo;t have an awareness of (or references back to) the array container.</p>

<pre><code class="ruby">    irb(main):004:0&gt; ObjectSpace.dump(ary)
    =&gt; "{\"address\":\"0x007fd24b890fd8\", \"type\":\"ARRAY\", \"class\":\"0x007fd24b872038\", \"length\":3, \"embedded\":true, \"references\":[\"0x007fd24b891050\", \"0x007fd24b891028\", \"0x007fd24b891000\"], \"file\":\"(irb)\", \"line\":3, \"method\":\"irb_binding\", \"generation\":7, \"flags\":{\"wb_protected\":true}}\n"
    irb(main):004:0&gt; ObjectSpace.reachable_objects_from(ary)
    =&gt; [Array, "a", "b", "c"]
    irb(main):006:0&gt; ObjectSpace.reachable_objects_from(ary[1])
    =&gt; [String]
    irb(main):007:0&gt; ObjectSpace.dump(ary[1])
    =&gt; "{\"address\":\"0x007fd24b891028\", \"type\":\"STRING\", \"class\":\"0x007fd24b829658\", \"embedded\":true, \"bytesize\":1, \"value\":\"b\", \"encoding\":\"UTF-8\", \"file\":\"(irb)\", \"line\":3, \"method\":\"irb_binding\", \"generation\":7, \"flags\":{\"wb_protected\":true, \"old\":true, \"marked\":true}}\n"
</code></pre>

<p>We stated earlier that:</p>

<p><strong>Young objects are more likely to reference old objects, than old objects referencing young objects. Old objects also frequently reference other old objects.</strong></p>

<p><em>However</em> it&rsquo;s possible for old objects to reference new objects. What happens when old objects reference new ones?</p>

<p>Old objects with references to new objects are stored in a &ldquo;remembered set&rdquo;. The remembered set is a container of references from old objects to new objects and is a shortcut for preventing heap scans for finding such references.</p>

<h2>Implications for Rails</h2>

<p>As our friend Ezra used to say, &ldquo;no code is faster than no code.&rdquo; The same applies to automatic memory management. Every object allocation also has a variable recycle cost. Allocation generally is low overhead as it happens once, except for the use case where there are no free object slots on the Ruby heap and a major GC is triggered as a result.</p>

<p>A major drawback of this limited segregation of OLD vs YOUNG is that <strong>many transient objects are in fact promoted to old during large contexts such as a Rails request</strong>. These long lived objects eventually become unexpected &ldquo;memory leaks&rdquo;. These transient objects can be conceptually classified as of &ldquo;medium lifetime&rdquo; as they need to stick around for the duration of a request. There&rsquo;s however a large probability that a minor GC would run during request lifetime, promoting young objects to old, effectively increasing their lifetime to well beyond the end of a request. This situation can only be revisited during a major GC which runs infrequently and sweeps both old and young objects.</p>

<p><strong>Each generation can be specifically tweaked, with the older generation being particularly important for balancing total process memory use with maintaining a minimal transient object set (young ones) per request. And subsequent too fast promotion from young to old generation.</strong></p>

<p><em>In our next post we will explore how you&rsquo;d approach tuning the Ruby GC for Rails applications, balancing tradeoffs of speed and memory. Leave your email address below and we&rsquo;ll let you know as soon as it&rsquo;s posted.</em></p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>See the Ruby Hacking Guide&rsquo;s <a href="https://ruby-hacking-guide.github.io/gc.html">GC chapter</a> for further context and nitty gritty details. I&rsquo;d recommended scanning the content below the first few headings, until turned off by C.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Rails Garbage Collection: Naive Defaults]]></title>
    <link href="https://bearmetal.eu/theden/rails-garbage-collection-naive-defaults/"/>
    <updated>2014-12-04T17:27:00+02:00</updated>
    <id>https://bearmetal.eu/theden/rails-garbage-collection-naive-defaults</id>
    <content type="html"><![CDATA[<p><a href="https://www.flickr.com/photos/x1klima/13349077375/in/photolist-mkBvCt-9F5bop-psoHyh-6pkzNo-9uDMLx-85EMnZ-ibSsrK-iog9vf-JtxCJ-iohdxP-ibS242-7RtfVT-k1H87W-jNAG6M-oxaFaw-cR3ow7-gEqUsd-6z6KY5-e1m1pQ-diRWXG-i5md69-iogg32-ibSVHi-ibStrn-ibSVUy-n8CpB1-67QKGw-p3qtEX-4THpny-ebLNCE-nycgpC-6U69md-4yXv5b-pTDf3R-861fmQ-6zABJu-3FKVM-nwzafz-6pgrY2-9ejbm6-QuSM-hvn32M-aomUMi-9eebae-b15Lpi-8tBhZj-6o1Xmn-6z3YKz-5s868-61WvU1"><img src="https://farm8.staticflickr.com/7036/13349077375_36fc92ecce_k_d.jpg" alt="" /></a></p>

<p><small>Photo by <a href="https://www.flickr.com/photos/x1klima/13349077375/in/photolist-mkBvCt-9F5bop-psoHyh-6pkzNo-9uDMLx-85EMnZ-ibSsrK-iog9vf-JtxCJ-iohdxP-ibS242-7RtfVT-k1H87W-jNAG6M-oxaFaw-cR3ow7-gEqUsd-6z6KY5-e1m1pQ-diRWXG-i5md69-iogg32-ibSVHi-ibStrn-ibSVUy-n8CpB1-67QKGw-p3qtEX-4THpny-ebLNCE-nycgpC-6U69md-4yXv5b-pTDf3R-861fmQ-6zABJu-3FKVM-nwzafz-6pgrY2-9ejbm6-QuSM-hvn32M-aomUMi-9eebae-b15Lpi-8tBhZj-6o1Xmn-6z3YKz-5s868-61WvU1">martin</a>, used under the Creative Commons license.</small></p>

<p>The vast majority of <a href="http://www.rubyonrails.org">Ruby on Rails</a> applications deploy to production with the vanilla Ruby GC configuration. A conservative combination of growth factors and accounting that &ldquo;works&rdquo; for a demographic from IRB sessions (still my preferred calculator) to massive monolithic Rails apps (the fate of most successful ones). In practice this doesn&rsquo;t work very well, however. It produces:</p>

<ul>
<li>Too aggressive growth of Ruby heap slots and pages when thresholds are reached.</li>
<li>A large ratio of short and medium lived objects in relation to long lived ones for Rails applications.</li>
<li>Too many intermittent major GC cycles during the request / response cycle.</li>
<li>Heap fragmentation.</li>
</ul>


<p>Let&rsquo;s use a metaphor most of us can better relate to: <em>dreaded household chores.</em> Your ability and frequency of hosting dinners at home are limited by four things (takeaways and paper plates aside):</p>

<ul>
<li>How many seats and tables you have</li>
<li>How many sets of clean cutlery, plates and glasses are available</li>
<li>Overhead preparing a particular choice of cuisine</li>
<li>Willingness to clean up and do dishes after</li>
</ul>


<p>This is what you have to work with at home:</p>

<ul>
<li>4 chairs and a table</li>
<li>12 plates and equivalent utensils</li>
<li>83 friends (60 from Facebook, 20 at work, your 2 brothers and then there&rsquo;s Jim)</li>
<li>3 wine glasses and a beer mug</li>
<li>1 bottle of wine and 24 beers<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></li>
<li>3 awesome steaks and a piece of tofu</li>
<li>Fresh local produce</li>
</ul>


<p>Some of your friends are also vegetarian.</p>

<p>Let&rsquo;s have a look at two different scenarios.</p>

<h4>IRB scenario</h4>

<p>You&rsquo;ve invited and subsequently prepared dinner and the table—seats, plates and cutlery sets—for four, popped open your bottle of wine and fired up the grill. However, only one friend arrives, quite late. You&rsquo;re grilling steak number three, yet he&rsquo;s the vegetarian…and only drinks beer. And even then doesn&rsquo;t talk very much.</p>

<p>In the end, you down the whole bottle of wine and the three steaks. Life&rsquo;s good again. There&rsquo;s plenty to clean up and pack away, still.</p>

<h4>Rails scenario</h4>

<p>17 guests show up at your door. Half of them are heavily intoxicated because Dylan invited the rest of his wine tasting group, too. Only one eats any of your food, yet breaks four plates. Beer disappeared in three minutes. The group members reveal seven new bottles of wine, make your dog drink one and he kernel panics as a result.</p>

<p>You were not f*cking prepared. At all. Marinated steak&rsquo;s now ruined, there&rsquo;s less inventory and 30+ bottles to recycle. You&rsquo;re hungry and now there are no plates left!</p>

<p>In both of these scenarios, from the perspective of your friends it mostly worked out just fine. It wasn&rsquo;t optimal for you or your environment, though. What&rsquo;s important is that you learned a few things:</p>

<ul>
<li>Next time it&rsquo;s easier to execute optimally, but there may still be a party and some broken plates.</li>
<li>A barbeque for 17 in your one bedroom flat with a George Foreman grill doesn&rsquo;t scale well.</li>
</ul>


<h2>Cooking with Ruby</h2>

<p>In the same manner, different use cases for the Ruby runtime require different preparations. Let&rsquo;s tie the dinner metaphor back to Ruby land and its memory model.</p>

<h4>Home environment</h4>

<p>The Ruby runtime, with everything else inside. Pages, objects and auxilary object data.</p>

<h4>Guest count</h4>

<p>The number of major features and facets you need to support. Gems and engines are good candidates along with individual models, controllers, views etc. These &ldquo;seats&rdquo; are also connected - different guests mingle together.</p>

<h4>Guest distribution</h4>

<p>Rails provides a framework for building applications, thus should be considered as part of the guest list too. Like some family members that make their way to gettogethers. First and second tier cousins you may hear of once a year and never talk with - they&rsquo;re present (consume memory), yet don&rsquo;t always add much value to the ambient.</p>

<h4>Food and drink</h4>

<p>The amount and distribution of objects required to make a feature or facet work. A mix bag of small entrees (embedded objects like 2-char strings), main dishes (a Rails request and all its context) to cocktails and tequila shots (threads!).</p>

<h4>Plates and glasses</h4>

<p>An object slot on the Ruby heap. One String, Array, Hash or any other object. Keep in mind that they can overflow and be recycled too - a wine glass is good for multiple servings. For buffets, a single plate can go very far too :-)</p>

<h4>Tables</h4>

<p>Ruby pages - containers for objects. All of the plates and glasses on a given table. They&rsquo;re mostly prepared in advance, but you can &ldquo;construct&rdquo; and improvise as needed to.</p>

<h4>Type of cuisine</h4>

<p>Some dishes incur a lot of work to prepare <em>and</em> to clean up. Cooked basmati rice will leave a very very different footprint in your kitchen than a paella or salmon option would.</p>

<p>The GC defaults for most Rails applications assume a reasonable sized home environment, a well defined guest list and just enough food and drinks for each. Everyone can sit at the same table, wine and dine on fine dishes, all with a minimal cleanup burden.</p>

<p><em>In reality, it&rsquo;s a frat party. Gone seriously wrong.</em></p>

<p><em>In the next part of this series, we&rsquo;re going to take a look at how the Ruby runtime can better host Rails applications. And what you can optimize for.</em></p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Because if there&rsquo;s a promotion, you buy.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
</feed>
